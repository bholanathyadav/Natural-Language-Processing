{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source - JCharisTech & J-Secur1ty YouTube Channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a document\n",
    "docx = nlp(\"Spacy is a cool tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spacy is a cool tool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx2 = nlp(u\"Spacy is an amazing tool like nltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spacy is an amazing tool like nltk"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open(u\"MyFile.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_file = nlp(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The subject of your research is very vast, profound and multi-dimensional. It\n",
       "requires passion, persistence and insights into human contradictions... And you\n",
       "seem to have all these qualities. I warmly wish you all the success in your work. If\n",
       "you like, you can contact Rufi in Paris. He might coordinate in many aspects. His\n",
       "e-mail is:"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_file2 = nlp(open(\"MyFile.txt\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The subject of your research is very vast, profound and multi-dimensional. It\n",
       "requires passion, persistence and insights into human contradictions... And you\n",
       "seem to have all these qualities. I warmly wish you all the success in your work. If\n",
       "you like, you can contact Rufi in Paris. He might coordinate in many aspects. His\n",
       "e-mail is:"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_file2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subject of your research is very vast, profound and multi-dimensional.\n",
      "It\n",
      "requires passion, persistence and insights into human contradictions...\n",
      "And you\n",
      "seem to have all these qualities.\n",
      "I warmly wish you all the success in your work.\n",
      "If\n",
      "you like, you can contact Rufi in Paris.\n",
      "He might coordinate in many aspects.\n",
      "His\n",
      "e-mail is:\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc_file.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: The subject of your research is very vast, profound and multi-dimensional.\n",
      "1: It\n",
      "requires passion, persistence and insights into human contradictions...\n",
      "2: And you\n",
      "seem to have all these qualities.\n",
      "3: I warmly wish you all the success in your work.\n",
      "4: If\n",
      "you like, you can contact Rufi in Paris.\n",
      "5: He might coordinate in many aspects.\n",
      "6: His\n",
      "e-mail is:\n"
     ]
    }
   ],
   "source": [
    "for num, sentence in enumerate(doc_file.sents):\n",
    "    print(f'{num}: {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spacy is a cool tool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy\n",
      "is\n",
      "a\n",
      "cool\n",
      "tool\n"
     ]
    }
   ],
   "source": [
    "for token in docx:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spacy', 'is', 'a', 'cool', 'tool']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of word tokens\n",
    "[token.text for token in docx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spacy', 'is', 'a', 'cool', 'tool']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to splitting on spaces\n",
    "docx.text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy 16072095006890171862 Xxxxx\n",
      "is 4370460163704169311 xx\n",
      "a 11123243248953317070 x\n",
      "cool 13110060611322374290 xxxx\n",
      "tool 13110060611322374290 xxxx\n"
     ]
    }
   ],
   "source": [
    "for word in docx:\n",
    "    print(word.text, word.shape, word.shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_doc = nlp(\"Hello hello HELLO HeLLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token => Hello Shape  Xxxxx True False\n",
      "Token => hello Shape  xxxx True False\n",
      "Token => HELLO Shape  XXXX True False\n",
      "Token => HeLLO Shape  XxXXX True False\n"
     ]
    }
   ],
   "source": [
    "for word in ex_doc:\n",
    "    print(\"Token =>\", word.text, \"Shape \", word.shape_, word.is_alpha, word.is_stop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
